\newglossaryentry{dense}{
    name={dense layer},
    description={Layer made out of multiple neurons; Also called hidden or fully connected layer}
}
\newglossaryentry{dropout}{
    name={dropout layer},
    description={Layer that sets random inputs to 0. Prevents overfittitng}
}
\newglossaryentry{batchnorm}{
    name={batch normalisation},
    description={Takes the average of an inputted batch of training data and normalizes them accordingly}
}
\newglossaryentry{overfitting}{
    name={overfitting},
    description={A process occurring when the model becomes to specified on the training data thus losing all generality}
}
\newglossaryentry{backpropagation}{
    name={backpropagation},
    description={The Process of adjusting the hyperparameters of a model from output to input using the gradients of the model}
}
\newglossaryentry{hyperparam}{
    name=hyperparameter,
    description={Parameter which have to be chosen when designing the model. Example: Depth of network or learning rate}
}
\newglossaryentry{pooling}{
    name=pooling,
    description={Reduces the size of an input matrix using for example the highest value(max pooling) in an area (pooling size)}
}
