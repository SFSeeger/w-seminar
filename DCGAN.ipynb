{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3483e32-a626-4a61-b2bd-1bfd62e797a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importing\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydot\n",
    "\n",
    "import kaggle\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())\n",
    "tf.get_logger().setLevel('INFO')\n",
    "#test GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "%load_ext tensorboard\n",
    "!rm -rf ./cDCGAN/logs/\n",
    "\n",
    "#base directory for execution\n",
    "BASE_DIR = \"/home/simon/Documents/W-Seminar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f2bd8-09f2-4472-8d60-1c24d1e9c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "#initialize optimizers\n",
    "generator_optimizer = keras.optimizers.Adam(2e-4)\n",
    "discriminator_optimizer = keras.optimizers.Adam(2e-4)\n",
    "\n",
    "#initialize loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f1798-9eaa-4c12-9466-8daebdea96c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "  os.path.join(BASE_DIR, \"dataset/preprocessed\"),\n",
    "  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "class_names = dataset.class_names\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "dataset = dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4bfa5-831b-42e5-bf8d-bf896d494064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in dataset.take(1).cache():\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow((images[i].numpy()*127.5+127.5).astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e8609-0a6e-4099-ac01-771d90b8e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build generator model\n",
    "def make_generator_model():\n",
    "    # latent vector input\n",
    "    gen_input = layers.Input((100,), name=\"latent_vector\")\n",
    "    \n",
    "    gen = layers.Dense(8*8*100, use_bias=False)(gen_input)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = layers.Reshape((8, 8, 100))(gen)\n",
    "    \n",
    "    # label input\n",
    "    label_input = layers.Input((1,), name=\"label\")\n",
    "    label = layers.Embedding(2, 50)(label_input)\n",
    "    label = layers.Dense(8*8)(label)\n",
    "    label = layers.Reshape((8,8,1))(label)\n",
    "    \n",
    "    # convert two inputs to one tensor\n",
    "    gen = layers.Concatenate()([gen, label])\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = layers.Dropout(0.5)(gen)\n",
    "\n",
    "    gen = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = layers.Dropout(0.5)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    out_layer = layers.Conv2D(3, (5, 5), padding=\"same\", use_bias=False,  activation='tanh')(gen)\n",
    "    \n",
    "    model = keras.Model([gen_input, label_input], out_layer)\n",
    "    assert out_layer.shape == (None, 64, 64,3)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852035de-af69-47e8-858c-3b1edc22720f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get summary\n",
    "generator = make_generator_model()\n",
    "generator.summary()\n",
    "tf.keras.utils.plot_model(generator, \"cDCGAN/cDCGenerator.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22abe8e-987c-4ab2-b168-39ac4e051e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define generator\n",
    "def make_discriminator_model(optimizer):\n",
    "    # label input\n",
    "    label_input = layers.Input((1,), name=\"label\")\n",
    "    label = layers.Embedding(2, 50)(label_input)\n",
    "    label = layers.Dense(64*64)(label)\n",
    "    label = layers.Reshape((64,64,1))(label)\n",
    "    \n",
    "    #image input\n",
    "    image_input = layers.Input((64, 64, 3), name=\"image\")\n",
    "    \n",
    "    # convert two inputs to one tensor\n",
    "    disc = layers.Concatenate()([image_input, label])\n",
    "    \n",
    "    disc = layers.Conv2D(64, (5, 5), strides=(2,2), padding='same')(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    \n",
    "    disc = layers.Conv2D(128, (5, 5), strides=(2,2), padding='same')(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    \n",
    "    disc = layers.Flatten()(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    output_layer = layers.Dense(1, activation='leaky_relu')(disc)\n",
    "    \n",
    "    model = keras.Model([image_input, label_input], output_layer)\n",
    "    model.compile(optimizer, loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"acc\"])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569f38e-a161-477e-8fe6-8319b1c47fb3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model(discriminator_optimizer)\n",
    "generator.summary()\n",
    "tf.keras.utils.plot_model(generator, \"cDCGAN/cDCDiscriminator.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adedbb-683a-441c-ad85-2559a734f592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317de47-764f-4641-9271-850f4d2b4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make gan model\n",
    "def make_gan_model(discrimiator: keras.Model, generator: keras.Model):\n",
    "    discrimiator.trainable = False\n",
    "    gen_noise_input, gen_label_input = generator.input\n",
    "    gen_output = generator.output\n",
    "    \n",
    "    gan_output = discrimiator([gen_output, gen_label_input])\n",
    "    model = keras.Model([gen_noise_input, gen_label_input], gan_output)\n",
    "    model.compile(generator_optimizer, loss=cross_entropy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef9fc8-d955-47a2-8a79-3a9cf7b5e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = make_gan_model(discriminator, generator)\n",
    "gan.summary()\n",
    "tf.keras.utils.plot_model(gan, \"cDCGAN/cDCGAN.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1951d4d-21a7-4e9d-87e2-d08033fa9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for image generation\n",
    "seed = tf.random.normal([16, 100])\n",
    "label_seed = np.random.randint(0,2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e99fc8-6c9d-4413-8245-2af8b33c2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint constants\n",
    "checkpoint_dir = 'cDCGAN/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator,)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa5017-643d-45f8-b54f-adf7e425816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise layer for reducing overfitting\n",
    "noise_layer = layers.GaussianNoise(0.2)\n",
    "\n",
    "def train_step(images, labels, candidate):\n",
    "    batch_size = images.shape[0]\n",
    "    noise = tf.random.normal([batch_size, 100])\n",
    "    fake_labels = np.random.randint(0,2, batch_size)\n",
    "\n",
    "    generated_images = generator.predict({\"latent_vector\":noise, \"label\":fake_labels}, verbose=0)\n",
    "    \n",
    "    noisy_generated_images = noise_layer(generated_images, training=False)\n",
    "    flipped_images = tf.image.random_flip_left_right(images)\n",
    "    noisy_images = noise_layer(flipped_images, training=False)\n",
    "    \n",
    "    \n",
    "    disc_loss_fake = 0.0\n",
    "    disc_loss_real = 0.0\n",
    "    gen_loss = 0.0\n",
    "    \n",
    "    # logic to train either generator, discriminator or both\n",
    "    if candidate == 0:\n",
    "        disc_loss_fake, _ = discriminator.train_on_batch([noisy_generated_images, fake_labels], tf.zeros([batch_size,1]))\n",
    "        disc_loss_real, _ = discriminator.train_on_batch([noisy_images, labels], tf.ones([batch_size,1]))\n",
    "    elif candidate == 1:\n",
    "        gen_loss = gan.train_on_batch([noise, fake_labels], tf.ones([batch_size,1]))\n",
    "    else:\n",
    "        disc_loss_fake, _ = discriminator.train_on_batch([noisy_generated_images, fake_labels], tf.zeros([batch_size,1]))\n",
    "        disc_loss_real, _ = discriminator.train_on_batch([noisy_images, labels], tf.ones([batch_size,1]))\n",
    "        gen_loss = gan.train_on_batch([noise, fake_labels], tf.ones([batch_size,1]))\n",
    "    \n",
    "    return gen_loss, disc_loss_real, disc_loss_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9d814-6f43-40df-8ad8-2f10c6e2ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHES = int(214692 / BATCH_SIZE)\n",
    "def train(dataset, epochs, start_epoch=0, save_checkpoints=True):\n",
    "    for epoch in range(start_epoch, epochs + start_epoch):\n",
    "        start = time.time()\n",
    "        batch = 1\n",
    "        train_condition = np.random.random([1,1])\n",
    "        #choose which model should be trained\n",
    "        if train_condition > 0 and train_condition < 0.25:\n",
    "            candidate = 0\n",
    "        elif train_condition > 0.25 and train_condition < 0.44:\n",
    "            candidate = 1\n",
    "        else:\n",
    "            candidate = 2\n",
    "        \n",
    "        for image_batch, labels in dataset:\n",
    "            gen_loss, disc_loss_real, disc_loss_fake = train_step(image_batch, labels, candidate)\n",
    "            print(f'{batch}/{BATCHES}: d_real={disc_loss_real} d_fake={disc_loss_fake} gan={gen_loss}', end=\"\\r\")\n",
    "            batch+=1\n",
    "                \n",
    "        print(f'd_real={disc_loss_real} d_fake={disc_loss_fake} gan={gen_loss}')\n",
    "        print(\"Time for epoch {}: {}\".format(epoch, time.time()-start))\n",
    "        \n",
    "        #generate images each epoch\n",
    "        generate_and_save_images(generator,epoch,seed, label_seed)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0 and save_checkpoints:\n",
    "            manager.save()\n",
    "            save_latest_epoch(epoch)\n",
    "            \n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input, labels):\n",
    "    predictions = model([test_input, labels], training=False).numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((predictions[i, :, :, :]*127.5+127.5).astype(\"int32\"))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(os.path.join(checkpoint_dir, \"images/\",'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b493008-550f-44ef-a82f-633268947626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latest training checkpoint and get latest epoch\n",
    "if manager.latest_checkpoint:\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    latest_epoch = int(manager.latest_checkpoint.split('-')[1])\n",
    "    last_epoch = latest_epoch * 15\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(last_epoch))\n",
    "else:\n",
    "    last_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9d5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c32556-987d-408e-a4c3-b2cfbfcc8441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enable tensorboard for logging\n",
    "LOG_DIR = \"cDCGAN/logs/fit\"\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(os.path.join(LOG_DIR, \"gen\"))\n",
    "tb_callback.set_model(generator)\n",
    "tb_disc_callback = tf.keras.callbacks.TensorBoard(os.path.join(LOG_DIR, \"disc\"))\n",
    "tb_callback.set_model(discriminator)\n",
    "\n",
    "%tensorboard --logdir cDCGAN/logs\n",
    "\n",
    "#train GAN for 5000 epochs\n",
    "train(dataset.prefetch(AUTOTUNE), 5000, last_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
