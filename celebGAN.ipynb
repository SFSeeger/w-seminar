{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85fc246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 10:30:12.140112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 10:30:12.859645: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-07 10:30:13.970574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simon/anaconda3/envs/tf/lib/\n",
      "2022-11-07 10:30:13.970703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simon/anaconda3/envs/tf/lib/\n",
      "2022-11-07 10:30:13.970708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055830be",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fecad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 214692 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 10:30:20.754268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:20.847481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:20.847590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:20.851621: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 10:30:20.852486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:20.852578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:20.852652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:22.026296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:22.027143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:22.027225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 10:30:22.027294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5395 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\"dataset/preprocessed\",\n",
    "  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "dataset = dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fbac531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 3)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              528384    \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 4096)              0         \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2D  (None, 8, 8, 256)        262144    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2D  (None, 16, 16, 128)      131072    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  (None, 32, 32, 64)       32768     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_15 (Conv2D  (None, 64, 64, 32)       8192      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 966,019\n",
      "Trainable params: 965,059\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_generator(latent_vector_shape, dense_shape):\n",
    "    latent_input = layers.Input(shape=latent_vector_shape)\n",
    "    gen = layers.Dense(4*4*dense_shape)(latent_input)\n",
    "    gen = layers.ReLU()(gen)\n",
    "    gen = layers.Reshape((4,4,dense_shape))(gen)\n",
    "    gen = layers.Dropout(0.2)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/2, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/4, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/8, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    \n",
    "    out = layers.Conv2D(3, (1, 1), strides=(1,1), activation='tanh')(gen)\n",
    "    \n",
    "    model: keras.Model = keras.Model(latent_input, out)\n",
    "    print(model.output_shape)\n",
    "    assert model.output_shape == (None, 64, 64, 3)\n",
    "    return model\n",
    "\n",
    "generator = make_generator(128, 256)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bf8468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 62, 62, 8)         224       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 31, 31, 8)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 31, 31, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 31, 31, 8)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 29, 29, 16)        1168      \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 14, 14, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 6, 6, 32)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                36896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,993\n",
      "Trainable params: 42,977\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_discriminator(input_shape):\n",
    "    image_input = layers.Input(input_shape)\n",
    "    \n",
    "    disc = layers.Conv2D(8, (3, 3))(image_input)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    disc = layers.BatchNormalization()(disc)\n",
    "    \n",
    "    \n",
    "    disc = layers.Conv2D(16, (3, 3))(disc)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    \n",
    "    disc = layers.Conv2D(32, (3, 3))(disc)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    \n",
    "    disc = layers.Flatten()(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    disc = layers.Dense(32)(disc)\n",
    "    out = layers.Dense(1)(disc)\n",
    "    \n",
    "    model = keras.Model(image_input, out)\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator((64, 64, 3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a92b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim=128, disc_extra_steps=3):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = disc_extra_steps\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        images, _ = data\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as gt:\n",
    "                generated_images = self.generator(latent_vector, training=True)\n",
    "                prediction_fake = self.discriminator(generated_images, training=True)\n",
    "                \n",
    "                flipped_images = tf.image.random_flip_left_right(images)\n",
    "                prediction_real = self.discriminator(flipped_images, training=True)\n",
    "                \n",
    "                d_loss = self.d_loss_fn(prediction_real, prediction_fake)\n",
    "            d_gradients = gt.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
    "            \n",
    "            latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as gt:\n",
    "                generated_images = self.generator(latent_vector, training=True)\n",
    "                prediction_fake = self.discriminator(generated_images, training=True)\n",
    "                g_loss = self.g_loss_fn(prediction_fake)\n",
    "                \n",
    "            g_gradients = gt.gradient(g_loss, self.generator.trainable_variables)\n",
    "            self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "            \n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c32664",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3e24a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'celebGAN/training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c2848fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"celebGAN/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "img_log_dir = \"celebGAN/logs/images/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(img_log_dir)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=16, latent_dim=100, start_epoch=0, seed=None):\n",
    "        self.num_img = num_img\n",
    "        if not seed == None:\n",
    "            self.seed = seed\n",
    "        else:\n",
    "            self.seed = tf.random.normal(shape=(num_img, latent_dim))\n",
    "        self.start_epoch = start_epoch\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generator(self.seed, training=False)\n",
    "        generated_images = (generated_images * 127.5) + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(generated_images[i, :, :, :].astype(\"int32\"))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.savefig(os.path.join(\"celebGAN/\", \"images/\",'image_at_epoch_{:04d}.png'.format(self.start_epoch+epoch)))\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.image(\"Output\", plot_to_image(fig), step=epoch)\n",
    "            \n",
    "class GANSaver(keras.callbacks.Callback):\n",
    "    def __init__(self, manager, num_epochs=15):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.manager = manager\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.num_epochs == 0:\n",
    "            self.manager.save()\n",
    "\n",
    "\n",
    "ckp = GANSaver(manager, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2daa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator, generator, latent_dim=128, disc_extra_steps=1)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, discriminator_loss, generator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b8992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No latest checkpoint found!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b5e079de03eaadf2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b5e079de03eaadf2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 0.9380 - g_loss: 1.4768\n",
      "Epoch 2/100\n",
      "839/839 [==============================] - 64s 76ms/step - d_loss: 1.2716 - g_loss: 0.8865\n",
      "Epoch 3/100\n",
      "839/839 [==============================] - 64s 76ms/step - d_loss: 1.2865 - g_loss: 0.9095\n",
      "Epoch 4/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.3103 - g_loss: 0.8172\n",
      "Epoch 5/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.3586 - g_loss: 0.7354\n",
      "Epoch 6/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.3258 - g_loss: 0.7970\n",
      "Epoch 7/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.2891 - g_loss: 0.8873\n",
      "Epoch 8/100\n",
      "839/839 [==============================] - 63s 74ms/step - d_loss: 1.2845 - g_loss: 0.8451\n",
      "Epoch 9/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.3475 - g_loss: 0.7999\n",
      "Epoch 10/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.2964 - g_loss: 0.8228\n",
      "Epoch 11/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.2708 - g_loss: 0.8852\n",
      "Epoch 12/100\n",
      "839/839 [==============================] - 62s 74ms/step - d_loss: 1.3063 - g_loss: 0.8156\n",
      "Epoch 13/100\n",
      "839/839 [==============================] - 63s 75ms/step - d_loss: 1.2412 - g_loss: 0.9276\n",
      "Epoch 14/100\n",
      "839/839 [==============================] - 63s 75ms/step - d_loss: 1.2985 - g_loss: 0.9004\n",
      "Epoch 15/100\n",
      "839/839 [==============================] - 64s 76ms/step - d_loss: 1.2745 - g_loss: 0.8224\n",
      "Epoch 16/100\n",
      "617/839 [=====================>........] - ETA: 16s - d_loss: 1.2931 - g_loss: 0.8351"
     ]
    }
   ],
   "source": [
    "if manager.latest_checkpoint:\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    latest_epoch = int(manager.latest_checkpoint.split('-')[1])\n",
    "    last_epoch = latest_epoch * 2\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(last_epoch))\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    print ('No latest checkpoint found!')\n",
    "ick = GANMonitor(num_img=16, latent_dim=128, start_epoch=last_epoch)\n",
    "\n",
    "%tensorboard --logdir celebGAN2/logs\n",
    "gan.fit(dataset, epochs=100, batch_size=256, callbacks=[ick, ckp, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d2c8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.save()\n",
    "seed = ick.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ef6b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = 25\n",
    "predictions = np.empty([100,64,64,3])\n",
    "for i in range(4):\n",
    "    seed = tf.random.normal([images, 128])\n",
    "    label_seed = np.random.randint(0,2, images)\n",
    "    pred = generator(seed, training=False).numpy()\n",
    "    predictions[25*i:25*(i+1), :, :, :] = pred\n",
    "    \n",
    "print(predictions.shape)\n",
    "figsize = 10\n",
    "fig = plt.figure(figsize=(figsize, figsize))  \n",
    "for i in range(predictions.shape[0]):\n",
    "    plt.subplot(figsize, figsize, i+1)\n",
    "    plt.imshow((predictions[i, :, :, :]*127.5+127.5).astype(\"int32\"))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaffeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(generator, \"celebGAN/Generator.png\", show_shapes=True)\n",
    "tf.keras.utils.plot_model(discriminator, \"celebGAN/Discriminator.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e87bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "generator.save(\"celebGAN/generator_model/generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b78f1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_weights(\"celebGAN/generator_model/weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
