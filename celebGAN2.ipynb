{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85fc246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 21:24:41.469584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 21:24:42.176720: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-07 21:24:43.282962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simon/anaconda3/envs/tf/lib/\n",
      "2022-11-07 21:24:43.283039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/simon/anaconda3/envs/tf/lib/\n",
      "2022-11-07 21:24:43.283044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# basic imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055830be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base Parameters\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fecad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset from storage\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\"dataset/preprocessed\",\n",
    "  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "dataset = dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbac531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 21:24:45.272961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:45.375294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:45.375532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:45.376606: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 21:24:45.376957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:45.377063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:45.377138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:46.734093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:46.734976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:46.735108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 21:24:46.735187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3796 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 3)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              528384    \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 4096)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 256)        262144    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8, 8, 256)        1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      131072    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 64)       32768     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 32)       8192      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 3)         1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 966,019\n",
      "Trainable params: 965,059\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define generator model\n",
    "def make_generator(latent_vector_shape, dense_shape):\n",
    "    latent_input = layers.Input(shape=latent_vector_shape)\n",
    "    gen = layers.Dense(4*4*dense_shape)(latent_input)\n",
    "    gen = layers.ReLU()(gen)\n",
    "    gen = layers.Reshape((4,4,dense_shape))(gen)\n",
    "    gen = layers.Dropout(0.2)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/2, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/4, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/8, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    \n",
    "    out = layers.Conv2D(3, (4, 4), strides=(1,1), padding=\"same\", activation='tanh')(gen)\n",
    "    \n",
    "    model: keras.Model = keras.Model(latent_input, out)\n",
    "    print(model.output_shape)\n",
    "    assert model.output_shape == (None, 64, 64, 3)\n",
    "    return model\n",
    "\n",
    "generator = make_generator(128, 256)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bf8468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 62, 62, 8)         224       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 31, 31, 8)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 31, 31, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 31, 31, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 29, 29, 16)        1168      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 14, 14, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 6, 6, 32)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                36896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,993\n",
      "Trainable params: 42,977\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define discriminator model\n",
    "def make_discriminator(input_shape):\n",
    "    image_input = layers.Input(input_shape)\n",
    "    \n",
    "    disc = layers.Conv2D(8, (3, 3))(image_input)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.BatchNormalization()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    \n",
    "    \n",
    "    disc = layers.Conv2D(16, (3, 3))(disc)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    \n",
    "    disc = layers.Conv2D(32, (3, 3))(disc)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    \n",
    "    disc = layers.Flatten()(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    disc = layers.Dense(32)(disc)\n",
    "    out = layers.Dense(1)(disc)\n",
    "    \n",
    "    model = keras.Model(image_input, out)\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator((64, 64, 3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a92b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GAN model\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim=128, disc_extra_steps=3):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = disc_extra_steps\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        images, _ = data\n",
    "        #calculate bacth size of current batch\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            #generate new latent vector\n",
    "            latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as gt:\n",
    "                # generate and predict images while being observed by gradient tape\n",
    "                # this allows backpropagation and automatic taking of the derivative\n",
    "                generated_images = self.generator(latent_vector, training=True)\n",
    "                prediction_fake = self.discriminator(generated_images, training=True)\n",
    "                \n",
    "                #flip images randomly to inttroduce variety\n",
    "                flipped_images = tf.image.random_flip_left_right(images)\n",
    "                prediction_real = self.discriminator(flipped_images, training=True)\n",
    "                \n",
    "                #calculate discriminator loss\n",
    "                d_loss = self.d_loss_fn(prediction_real, prediction_fake)\n",
    "            #calculate discriminator gradients\n",
    "            d_gradients = gt.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            #apply gradients using Adam\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
    "            \n",
    "            #generate new latent vector for generator training\n",
    "            latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as gt:\n",
    "                # generate and predict images while being observed by gradient tape\n",
    "                # this allows backpropagation and automatic taking of the derivative\n",
    "                generated_images = self.generator(latent_vector, training=True)\n",
    "                prediction_fake = self.discriminator(generated_images, training=True)\n",
    "                #calculate generator loss\n",
    "                g_loss = self.g_loss_fn(prediction_fake)\n",
    "               \n",
    "            #calculate gradients and apply them using Adam\n",
    "            g_gradients = gt.gradient(g_loss, self.generator.trainable_variables)\n",
    "            self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "            \n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c32664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Loss functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "#initalize optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e24a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Checkpoint saving if training gets interrupted\n",
    "checkpoint_dir = 'celebGAN2/training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2848fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"celebGAN2/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "img_log_dir = \"celebGAN2/logs/images/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(img_log_dir)\n",
    "\n",
    "# Method converting matplotlib figures to images usable by tensorboard\n",
    "# Source https://www.tensorflow.org/tensorboard/image_summaries\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Save Image every epoch\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=16, latent_dim=100, start_epoch=0, seed=None):\n",
    "        self.num_img = num_img\n",
    "        if not seed == None:\n",
    "            self.seed = seed\n",
    "        else:\n",
    "            self.seed = tf.random.normal(shape=(num_img, latent_dim))\n",
    "        self.start_epoch = start_epoch\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generator(self.seed, training=False)\n",
    "        generated_images = (generated_images * 127.5) + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        \n",
    "        #generate a subplot\n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(generated_images[i, :, :, :].astype(\"int32\"))\n",
    "            plt.axis('off')\n",
    "\n",
    "        #save to harddrive\n",
    "        plt.savefig(os.path.join(\"celebGAN2/\", \"images/\",'image_at_epoch_{:04d}.png'.format(self.start_epoch+epoch)))\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.image(\"Output\", plot_to_image(fig), step=epoch)\n",
    "\n",
    "# Save Checkpoint every 2 epochs\n",
    "class GANSaver(keras.callbacks.Callback):\n",
    "    def __init__(self, manager, num_epochs=15):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.manager = manager\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.num_epochs == 0:\n",
    "            self.manager.save()\n",
    "\n",
    "\n",
    "ckp = GANSaver(manager, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2daa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator, generator, latent_dim=128, disc_extra_steps=1)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, discriminator_loss, generator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b8992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#restore latest state of training\n",
    "if manager.latest_checkpoint:\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    latest_epoch = int(manager.latest_checkpoint.split('-')[1])\n",
    "    last_epoch = latest_epoch * 2\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(last_epoch))\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    print ('No latest checkpoint found!')\n",
    "#initialize image saver with start epoch variable to keep existing images after restart\n",
    "ick = GANMonitor(num_img=16, latent_dim=128, start_epoch=last_epoch)\n",
    "\n",
    "#start tensorboard\n",
    "%tensorboard --logdir celebGAN2/logs\n",
    "#train model on the dataset for 100 epochs\n",
    "gan.fit(dataset, epochs=100, batch_size=256, callbacks=[ick, ckp, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to harddrive\n",
    "manager.save()\n",
    "# store seed in variable to keep faces consistent when rerun\n",
    "seed = ick.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ef6b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#generate 100 sample images in batches\n",
    "images = 25\n",
    "predictions = np.empty([100,64,64,3])\n",
    "for i in range(4):\n",
    "    seed = tf.random.normal([images, 128])\n",
    "    label_seed = np.random.randint(0,2, images)\n",
    "    pred = generator(seed, training=False).numpy()\n",
    "    predictions[25*i:25*(i+1), :, :, :] = pred\n",
    "    \n",
    "print(predictions.shape)\n",
    "figsize = 10\n",
    "fig = plt.figure(figsize=(figsize, figsize))  \n",
    "for i in range(predictions.shape[0]):\n",
    "    plt.subplot(figsize, figsize, i+1)\n",
    "    plt.imshow((predictions[i, :, :, :]*127.5+127.5).astype(\"int32\"))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaffeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the Generator and Discriminator as Image\n",
    "tf.keras.utils.plot_model(generator, \"celebGAN/Generator.png\", show_shapes=True)\n",
    "tf.keras.utils.plot_model(discriminator, \"celebGAN/Discriminator.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e87bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# save Generator as h5 model to use in e.g. matlab\n",
    "generator.save(\"celebGAN2/generator_model/celebGAN2generator.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
