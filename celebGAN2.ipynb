{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85fc246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "055830be",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fecad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 214692 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\"dataset/preprocessed\",\n",
    "  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "dataset = dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fbac531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 3)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              528384    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 4096)              0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 8, 8, 256)        262144    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 16, 16, 128)      131072    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 32, 32, 64)       32768     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 64, 64, 32)       8192      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 3)         1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 966,019\n",
      "Trainable params: 965,059\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_generator(latent_vector_shape, dense_shape):\n",
    "    latent_input = layers.Input(shape=latent_vector_shape)\n",
    "    gen = layers.Dense(4*4*dense_shape)(latent_input)\n",
    "    gen = layers.ReLU()(gen)\n",
    "    gen = layers.Reshape((4,4,dense_shape))(gen)\n",
    "    gen = layers.Dropout(0.2)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/2, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/4, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    gen = layers.Dropout(0.25)(gen)\n",
    "    \n",
    "    gen = layers.Conv2DTranspose(dense_shape/8, (2, 2), 2, use_bias=False)(gen)\n",
    "    gen = layers.BatchNormalization()(gen)\n",
    "    gen = layers.LeakyReLU()(gen)\n",
    "    \n",
    "    out = layers.Conv2D(3, (4, 4), strides=(1,1), padding=\"same\", activation='tanh')(gen)\n",
    "    \n",
    "    model: keras.Model = keras.Model(latent_input, out)\n",
    "    print(model.output_shape)\n",
    "    assert model.output_shape == (None, 64, 64, 3)\n",
    "    return model\n",
    "\n",
    "generator = make_generator(128, 256)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bf8468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 62, 62, 8)         224       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 31, 31, 8)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 31, 31, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 31, 31, 8)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 29, 29, 16)        1168      \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 14, 14, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 6, 6, 32)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                36896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,993\n",
      "Trainable params: 42,977\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_discriminator(input_shape):\n",
    "    image_input = layers.Input(input_shape)\n",
    "    \n",
    "    disc = layers.Conv2D(8, (3, 3))(image_input)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.BatchNormalization()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    \n",
    "    \n",
    "    disc = layers.Conv2D(16, (3, 3))(disc)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    \n",
    "    disc = layers.Conv2D(32, (3, 3))(disc)\n",
    "    disc = layers.AveragePooling2D()(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.02)(disc)\n",
    "    \n",
    "    disc = layers.Flatten()(disc)\n",
    "    disc = layers.Dropout(0.3)(disc)\n",
    "    disc = layers.Dense(32)(disc)\n",
    "    out = layers.Dense(1)(disc)\n",
    "    \n",
    "    model = keras.Model(image_input, out)\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator((64, 64, 3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a92b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim=128, disc_extra_steps=3):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = disc_extra_steps\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        images, _ = data\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as gt:\n",
    "                generated_images = self.generator(latent_vector, training=True)\n",
    "                prediction_fake = self.discriminator(generated_images, training=True)\n",
    "                \n",
    "                flipped_images = tf.image.random_flip_left_right(images)\n",
    "                prediction_real = self.discriminator(flipped_images, training=True)\n",
    "                \n",
    "                d_loss = self.d_loss_fn(prediction_real, prediction_fake)\n",
    "            d_gradients = gt.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
    "            \n",
    "            latent_vector = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as gt:\n",
    "                generated_images = self.generator(latent_vector, training=True)\n",
    "                prediction_fake = self.discriminator(generated_images, training=True)\n",
    "                g_loss = self.g_loss_fn(prediction_fake)\n",
    "                \n",
    "            g_gradients = gt.gradient(g_loss, self.generator.trainable_variables)\n",
    "            self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "            \n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8c32664",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3e24a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'celebGAN2/training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2848fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"celebGAN2/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "img_log_dir = \"celebGAN2/logs/images/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(img_log_dir)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=16, latent_dim=100, start_epoch=0, seed=None):\n",
    "        self.num_img = num_img\n",
    "        if not seed == None:\n",
    "            self.seed = seed\n",
    "        else:\n",
    "            self.seed = tf.random.normal(shape=(num_img, latent_dim))\n",
    "        self.start_epoch = start_epoch\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generator(self.seed, training=False)\n",
    "        generated_images = (generated_images * 127.5) + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(generated_images[i, :, :, :].astype(\"int32\"))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.savefig(os.path.join(\"celebGAN2/\", \"images/\",'image_at_epoch_{:04d}.png'.format(self.start_epoch+epoch)))\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.image(\"Output\", plot_to_image(fig), step=epoch)\n",
    "            \n",
    "class GANSaver(keras.callbacks.Callback):\n",
    "    def __init__(self, manager, num_epochs=15):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.manager = manager\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.num_epochs == 0:\n",
    "            self.manager.save()\n",
    "\n",
    "\n",
    "ckp = GANSaver(manager, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2daa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator, generator, latent_dim=128, disc_extra_steps=1)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, discriminator_loss, generator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b8992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint of epoch 284 restored!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-794a7d3f5407b4d2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-794a7d3f5407b4d2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "839/839 [==============================] - 69s 80ms/step - d_loss: 1.2699 - g_loss: 0.8348\n",
      "Epoch 2/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2379 - g_loss: 0.8751\n",
      "Epoch 3/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2498 - g_loss: 0.8598\n",
      "Epoch 4/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2696 - g_loss: 0.8364\n",
      "Epoch 5/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2470 - g_loss: 0.8638\n",
      "Epoch 6/100\n",
      "839/839 [==============================] - 68s 80ms/step - d_loss: 1.2353 - g_loss: 0.8815\n",
      "Epoch 7/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2326 - g_loss: 0.8780\n",
      "Epoch 8/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2559 - g_loss: 0.8550\n",
      "Epoch 9/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2489 - g_loss: 0.8617\n",
      "Epoch 10/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2545 - g_loss: 0.8552\n",
      "Epoch 11/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2596 - g_loss: 0.8517\n",
      "Epoch 12/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2457 - g_loss: 0.8652\n",
      "Epoch 13/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2365 - g_loss: 0.8711\n",
      "Epoch 14/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2473 - g_loss: 0.8713\n",
      "Epoch 15/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2336 - g_loss: 0.8739\n",
      "Epoch 16/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2574 - g_loss: 0.8442\n",
      "Epoch 17/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2538 - g_loss: 0.8558\n",
      "Epoch 18/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2478 - g_loss: 0.8636\n",
      "Epoch 19/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2389 - g_loss: 0.8632\n",
      "Epoch 20/100\n",
      "839/839 [==============================] - 67s 79ms/step - d_loss: 1.2541 - g_loss: 0.8631\n",
      "Epoch 21/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2453 - g_loss: 0.8634\n",
      "Epoch 22/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2559 - g_loss: 0.8527\n",
      "Epoch 23/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2575 - g_loss: 0.8497\n",
      "Epoch 24/100\n",
      "839/839 [==============================] - 68s 80ms/step - d_loss: 1.2441 - g_loss: 0.8692\n",
      "Epoch 25/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2516 - g_loss: 0.8541\n",
      "Epoch 26/100\n",
      "839/839 [==============================] - 69s 82ms/step - d_loss: 1.2451 - g_loss: 0.8612\n",
      "Epoch 27/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2609 - g_loss: 0.8505\n",
      "Epoch 28/100\n",
      "839/839 [==============================] - 67s 80ms/step - d_loss: 1.2595 - g_loss: 0.8434\n",
      "Epoch 29/100\n",
      "839/839 [==============================] - 68s 81ms/step - d_loss: 1.2479 - g_loss: 0.8628\n",
      "Epoch 30/100\n",
      "839/839 [==============================] - 69s 82ms/step - d_loss: 1.2609 - g_loss: 0.8475\n",
      "Epoch 31/100\n",
      "839/839 [==============================] - 69s 82ms/step - d_loss: 1.2490 - g_loss: 0.8614\n",
      "Epoch 32/100\n",
      "839/839 [==============================] - 70s 83ms/step - d_loss: 1.2509 - g_loss: 0.8536\n",
      "Epoch 33/100\n",
      "839/839 [==============================] - 69s 82ms/step - d_loss: 1.2521 - g_loss: 0.8595\n",
      "Epoch 34/100\n",
      "839/839 [==============================] - 69s 82ms/step - d_loss: 1.2496 - g_loss: 0.8604\n",
      "Epoch 35/100\n",
      "839/839 [==============================] - 69s 82ms/step - d_loss: 1.2490 - g_loss: 0.8579\n",
      "Epoch 36/100\n",
      "205/839 [======>.......................] - ETA: 51s - d_loss: 1.2387 - g_loss: 0.8824"
     ]
    }
   ],
   "source": [
    "if manager.latest_checkpoint:\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    latest_epoch = int(manager.latest_checkpoint.split('-')[1])\n",
    "    last_epoch = latest_epoch * 2\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(last_epoch))\n",
    "else:\n",
    "    last_epoch = 0\n",
    "    print ('No latest checkpoint found!')\n",
    "ick = GANMonitor(num_img=16, latent_dim=128, start_epoch=last_epoch)\n",
    "\n",
    "%tensorboard --logdir celebGAN2/logs\n",
    "gan.fit(dataset, epochs=100, batch_size=256, callbacks=[ick, ckp, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.save()\n",
    "seed = ick.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ef6b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = 25\n",
    "predictions = np.empty([100,64,64,3])\n",
    "for i in range(4):\n",
    "    seed = tf.random.normal([images, 128])\n",
    "    label_seed = np.random.randint(0,2, images)\n",
    "    pred = generator(seed, training=False).numpy()\n",
    "    predictions[25*i:25*(i+1), :, :, :] = pred\n",
    "    \n",
    "print(predictions.shape)\n",
    "figsize = 10\n",
    "fig = plt.figure(figsize=(figsize, figsize))  \n",
    "for i in range(predictions.shape[0]):\n",
    "    plt.subplot(figsize, figsize, i+1)\n",
    "    plt.imshow((predictions[i, :, :, :]*127.5+127.5).astype(\"int32\"))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaffeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(generator, \"celebGAN/Generator.png\", show_shapes=True)\n",
    "tf.keras.utils.plot_model(discriminator, \"celebGAN/Discriminator.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"celebGAN/generator_model/generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_weights(\"celebGAN/generator_model/weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
